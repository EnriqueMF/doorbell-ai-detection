{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Doorbell Detection Model Training\n",
        "\n",
        "This notebook trains a machine learning model to detect doorbell sounds from audio recordings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n",
        "\n",
        "Import all necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# Import our custom audio processing utilities\n",
        "from doorbell_detection_utils import process_dataset, extract_features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure Directories and Parameters\n",
        "\n",
        "Set up paths and audio processing parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define parameters for audio processing and feature extraction\n",
        "sample_rate = 16000\n",
        "segment_duration = 1.0    # in seconds\n",
        "hop_duration = 0.5        # in seconds\n",
        "n_mfcc = 20               # Number of MFCC coefficients\n",
        "n_mels = 40               # Number of Mel bands\n",
        "n_fft = 1024              # FFT window size\n",
        "hop_length = 512          # Hop length for FFT\n",
        "augment = True            # Whether to apply data augmentation\n",
        "n_max_background_samples = 2000  # Maximum number of negative examples\n",
        "n_max_mixed_samples_coef = 0.3   # Coefficient to calculate the maximum number of mixed examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load and Process Audio Data\n",
        "\n",
        "Now we'll process the audio files and extract features for our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set paths for audio files\n",
        "audio_samples_path = './audio_samples'\n",
        "os.makedirs(audio_samples_path, exist_ok=True)\n",
        "print(f\"Audio samples directory: {audio_samples_path}\")\n",
        "\n",
        "# Check if doorbell audio file exists\n",
        "doorbell_path_mp3 = os.path.join(audio_samples_path, 'doorbell.mp3')\n",
        "doorbell_path_wav = os.path.join(audio_samples_path, 'doorbell.wav')\n",
        "if os.path.exists(doorbell_path_mp3):\n",
        "    doorbell_path = doorbell_path_mp3\n",
        "elif os.path.exists(doorbell_path_wav):\n",
        "    doorbell_path = doorbell_path_wav\n",
        "else:\n",
        "    print(\"ERROR: doorbell.mp3 or doorbell.wav not found!\")\n",
        "    print(\"Please add your doorbell recording as 'doorbell.mp3' or 'doorbell.wav' in the audio_samples folder\")\n",
        "    print(\"The model training will not be effective without a doorbell sample.\")\n",
        "    doorbell_path = None\n",
        "    \n",
        "if doorbell_path:\n",
        "    print(f\"Doorbell sample found: {doorbell_path}\")\n",
        "    # Process audio data and extract features\n",
        "    features, labels = process_dataset(\n",
        "        doorbell_path=doorbell_path,\n",
        "        audio_dirs=[audio_samples_path],\n",
        "        sample_rate=sample_rate,\n",
        "        segment_duration=segment_duration,\n",
        "        hop_duration=hop_duration,\n",
        "        n_mfcc=n_mfcc,\n",
        "        n_mels=n_mels,\n",
        "        n_fft=n_fft,\n",
        "        hop_length=hop_length,\n",
        "        augment=augment,\n",
        "        mix_background=True,\n",
        "        mix_ratio_range=(0.1, 0.5),                     # Proportion mix of background and doorbell\n",
        "        max_background_samples=n_max_background_samples, # Limit of negative examples\n",
        "        max_mixed_samples=n_max_background_samples*n_max_mixed_samples_coef # Mixed examples to generate\n",
        ")\n",
        "else:\n",
        "    print(\"ERROR: doorbell.mp3 or doorbell.wav not found!\")\n",
        "    print(\"Please add your doorbell recording as 'doorbell.mp3' or 'doorbell.wav' in the audio_samples folder\")\n",
        "    print(\"The model training will not be effective without a doorbell sample.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Explore Processed Data\n",
        "\n",
        "Let's examine the extracted features and check the balance of our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display information about the dataset\n",
        "print(f\"Total samples: {len(features)}\")\n",
        "print(f\"Number of features per sample: {features.shape[1]}\")\n",
        "print(f\"Doorbell samples: {np.sum(labels)}\")\n",
        "print(f\"Background noise samples: {len(labels) - np.sum(labels)}\")\n",
        "print(f\"Class balance: {np.sum(labels) / len(labels):.2%} doorbell vs {1 - np.sum(labels) / len(labels):.2%} background\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Split Data into Training and Validation Sets\n",
        "\n",
        "We'll use stratified sampling to maintain the class distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the dataset\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    features, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
        "print(f\"Training set distribution: {np.sum(y_train)} doorbell, {len(y_train) - np.sum(y_train)} background sounds\")\n",
        "print(f\"Validation set distribution: {np.sum(y_val)} doorbell, {len(y_val) - np.sum(y_val)} background souds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Define the Model Architecture\n",
        "\n",
        "We'll create a simple neural network with dropout for regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        ")\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train the Model\n",
        "\n",
        "We'll use early stopping to prevent overfitting and learning rate reduction to improve convergence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=0.0001,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluate the Model\n",
        "\n",
        "Let's check how well our model performs by analyzing metrics and visualizing results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on validation set\n",
        "y_pred_prob = model.predict(X_val)\n",
        "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "precision = precision_score(y_val, y_pred)\n",
        "recall = recall_score(y_val, y_pred)\n",
        "f1 = f1_score(y_val, y_pred)\n",
        "\n",
        "# Print metrics\n",
        "print(\"\\nModel Evaluation:\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(f\"True Positives: {conf_matrix[1][1]}\")\n",
        "print(f\"False Positives: {conf_matrix[0][1]}\")\n",
        "print(f\"True Negatives: {conf_matrix[0][0]}\")\n",
        "print(f\"False Negatives: {conf_matrix[1][0]}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(history.history['precision'])\n",
        "plt.plot(history.history['val_precision'])\n",
        "plt.plot(history.history['recall'])\n",
        "plt.plot(history.history['val_recall'])\n",
        "plt.title('Precision & Recall')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Precision', 'Val Precision', 'Recall', 'Val Recall'], loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize predictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(range(len(y_val)), y_pred_prob, c=y_val, cmap='coolwarm', alpha=0.6)\n",
        "plt.axhline(y=0.5, color='r', linestyle='-')\n",
        "plt.title('Model Predictions')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Prediction Probability')\n",
        "plt.colorbar(label='Actual Class')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Save the Model\n",
        "\n",
        "Let's save our trained model for deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create directory for models if it not exists\n",
        "models_dir = '../models'\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "# Save in H5 format (TensorFlow/Keras)\n",
        "model_path = os.path.join(models_dir, 'doorbell_detector.h5')\n",
        "model.save(model_path)\n",
        "print(f\"Model saved to {model_path}\")\n",
        "\n",
        "# Convert to TFLite format (embedded devices)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "tflite_model_path = os.path.join(models_dir, 'doorbell_detector.tflite')\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "print(f\"TFLite model saved to {tflite_model_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
